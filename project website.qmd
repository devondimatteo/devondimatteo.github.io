---
title: "NCAA Basketball Regression"
subtitle: "DANL310 Project" 
author: 
  - "Alec Eng"
  - "Devon DiMatteo"
  - <br>
date: "2023-05-04<br><br>"
format: 
  html:
    code-fold: True
    
---
<br><br>

```{r setup, include=FALSE}
library(tidyverse)
library(knitr)


```


<br> 

# Introduction
- Why does your research project matter
- Motive for project
- Summarize the project in the last paragraph

# Data
- Summary statistics (Use `skimr::skim()`)

# Conceptual Framework
- Justify your ML model.
 - Why the model considers the variables in the model.

# Model 
- Add some model equation

Empirical Model:

$$y_{i} = \beta_{0} + \beta_{1}ADJOE + \beta_{2}ADJDE + \beta_{3}EFG_O + \beta_{4}{EFG\_D}_{i} + \beta_{5}TOR_{i} + \beta_{6}TORD_{i} + \beta_{7}2{P\_O}_{i} + \beta_{8}2{P\_D}_{i} + \beta_{9}3{P\_O}_{i} + \beta_{10}SEED_{i} + \beta_{11}WAB_{i} +  \epsilon_{i}$$

$$y_{i} = \beta_{0} + \beta_{1}X_{i} + \beta_{2}X_{2i} +  \epsilon_{i}$$
##Creating the model in Python

```{r}
library(readxl)
df <- read_excel("C:\\Users\\Devon DiMatteo\\Desktop\\danl310df.xlsx")

```

```{python}
import pandas as pd
import numpy as np
import statsmodels.api as sm

```

The packages that are used to create the model are `numpy`, `pandas`, and `statsmodels.apu`
The first step in the code is to pull the variables that will be used in the regression.

```{python}
data=pd.read_excel("C:\\Users\\Devon DiMatteo\\Desktop\\danl310df.xlsx")
cbb_data=data.copy()
cbb = cbb_data[[ "W", "ADJOE", "ADJDE", "EFG_O", "EFG_D", "TOR", "TORD", "2P_O","2P_D", "3P_O","3P_D", "SEED", "WAB" ]]
cbb
```

Next we split the features and the labels into different datasets using the `.drop` function

```{python}
cbb_features=cbb.drop("SEED", axis="columns")
cbb_labels=cbb["SEED"]
```

###Linear Regression Model

For the linear regression model we use scikit-learn software to run the machine 
learning model. 

```{python}
from sklearn.linear_model import LinearRegression
lin_reg=LinearRegression()
lin_reg.fit(cbb_features, cbb_labels)
```

###Decision Tree Model

We also use the scikit-learn software for the dicision tree regression

The following code is training the model:
```{python}
from sklearn.tree import DecisionTreeRegressor
tree_reg=DecisionTreeRegressor()
tree_reg.fit(cbb_features, cbb_labels)
```

```{python}
from sklearn.metrics import mean_squared_error
cbb_predictions2=tree_reg.predict(cbb_features)
tree_mse=mean_squared_error(cbb_labels, cbb_predictions2)

import numpy as np
tree_rmse=np.sqrt(tree_mse)

print(tree_rmse)
```


# Results

### Linear Regression Coefficents 
```{python}
lin_reg.coef_
```

### Linear Regression p-values


```{python}
X = sm.add_constant(cbb_features)  # add a constant term to the independent variables
results = sm.OLS(cbb_labels, cbb_features).fit()
p_values = results.pvalues

# print the coefficients and p-values
print("Coefficients:", lin_reg.coef_)
print("P-values:", p_values[0:])
```

- summarize the main results of the model you want to focus on 
 - pridected outcomes
 

- Which model performed the best
 - Mean squared errors
 residual plots

# Discussion
- Discuss the implication of your model result
- You can make suggestions for strategy 

# Conclusion
- Summarize the project
- Mention future work 














#Project

# Model 

```{python}
import pandas as pd
import numpy as np
import statsmodels.api as sm

```

```{python}
data=pd.read_excel("C:\\Users\\Devon DiMatteo\\Desktop\\danl310df.xlsx")
cbb_data=data.copy()
cbb = cbb_data[[ "W", "ADJOE", "ADJDE", "EFG_O", "EFG_D", "TOR", "TORD", "2P_O","2P_D", "3P_O","3P_D", "SEED", "WAB" ]]
cbb
```

```{python}
cbb_data.info()
```

```{python}
cbb.info()
```

```{python}
cbb_features=cbb.drop("SEED", axis="columns")
cbb_labels=cbb["SEED"]
```

#Linear Regression Model

```{python}
from sklearn.linear_model import LinearRegression
lin_reg=LinearRegression()
lin_reg.fit(cbb_features, cbb_labels)
```
```{python}
lin_reg.coef_
```

```{python}
X = sm.add_constant(cbb_features)  # add a constant term to the independent variables
results = sm.OLS(cbb_labels, cbb_features).fit()
p_values = results.pvalues

# print the coefficients and p-values
print("Coefficients:", lin_reg.coef_)
print("P-values:", p_values[0:])
```

```{python}
alpha = 0.05
significant_coeffs = [i for i in range(len(p_values)) if p_values[i] < alpha]
print("Significant coefficients:", significant_coeffs)
```


```{python}
from sklearn.metrics import mean_squared_error
cbb_predictions=lin_reg.predict(cbb_features)
lin_mse=mean_squared_error(cbb_labels,cbb_predictions)

import numpy as np
lin_rmse=np.sqrt(lin_mse)

print(lin_rmse)
```

#Decision Tree Model

```{python}
from sklearn.tree import DecisionTreeRegressor
tree_reg=DecisionTreeRegressor()
tree_reg.fit(cbb_features, cbb_labels)
```

```{python}
from sklearn.metrics import mean_squared_error
cbb_predictions2=tree_reg.predict(cbb_features)
tree_mse=mean_squared_error(cbb_labels, cbb_predictions2)

import numpy as np
tree_rmse=np.sqrt(tree_mse)

print(tree_rmse)
```
```{python}
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import cross_val_score

# evaluate the model using cross-validation
scores = cross_val_score(tree_reg, cbb_features, cbb_labels, cv=5)
print("Cross-validation scores:", scores)
print("Mean score:", scores.mean())
# -15 is a sign of overfitting
```

```{python}
print("Feature importances:", tree_reg.feature_importances_)
```


#Random Forest

```{python}
from sklearn.ensemble import RandomForestRegressor
forest_reg=RandomForestRegressor()
forest_reg.fit(cbb_features,cbb_labels)
```
```{python}
from sklearn.metrics import mean_squared_error
cbb_predictions3=forest_reg.predict(cbb_features)
forest_mse=mean_squared_error(cbb_labels, cbb_predictions3)
forest_rmse=np.sqrt(forest_mse)
```

```{python}
print(forest_rmse)
```

```{python}
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import cross_val_score

# evaluate the model using cross-validation
scores = cross_val_score(forest_reg, cbb_features, cbb_labels, cv=5)
print("Cross-validation scores:", scores)
print("Mean score:", scores.mean())
```



```{python}
print("Feature importances:", forest_reg.feature_importances_)
```








